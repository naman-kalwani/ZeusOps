{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPL0nyxFOOt0qJEXUyG7JdP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoqhlpmsLWC9","executionInfo":{"status":"ok","timestamp":1759080655263,"user_tz":-330,"elapsed":3915,"user":{"displayName":"Lekzang Jigme","userId":"15030187845076288727"}},"outputId":"1fc89ec3-e4b2-41b1-d055-126822faf2a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# --- Imports ---\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import joblib\n","from sklearn.preprocessing import MinMaxScaler, label_binarize\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n","from xgboost import XGBClassifier\n","from tensorflow.keras.models import load_model\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# --- Paths (UNSW-NB15 dataset) ---\n","DATA_DIR = Path(\"/content/drive/MyDrive/zeusOps/data/UNSW-NB15\")\n","MODEL_DIR = Path(\"/content/drive/MyDrive/zeusOps/models\")\n","\n","# --- Load Preprocessed Data (multiclass labels for UNSW) ---\n","X_train = pd.read_pickle(DATA_DIR / \"unsw_x_train.pkl\")\n","X_test  = pd.read_pickle(DATA_DIR / \"unsw_x_test.pkl\")\n","y_train = pd.read_pickle(DATA_DIR / \"unsw_y_train.pkl\")\n","y_test  = pd.read_pickle(DATA_DIR / \"unsw_y_test.pkl\")\n","\n","# --- Load Pretrained Models ---\n","if_model = joblib.load(MODEL_DIR / \"unsw_if.pkl\")\n","dae_model = load_model(MODEL_DIR / \"unsw_dae_model.h5\", compile=False)\n","\n","# Convert to numpy\n","X_train = X_train.values if hasattr(X_train, \"values\") else np.array(X_train)\n","X_test  = X_test.values if hasattr(X_test, \"values\") else np.array(X_test)\n","y_train = np.array(y_train).ravel()\n","y_test  = np.array(y_test).ravel()\n","\n","print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n","\n","# --- Step 1: Get Anomaly Scores ---\n","if_scores_train = -if_model.decision_function(X_train)\n","if_scores_test  = -if_model.decision_function(X_test)\n","\n","X_train_recon = dae_model.predict(X_train, verbose=0)\n","X_test_recon  = dae_model.predict(X_test, verbose=0)\n","\n","dae_scores_train = np.mean((X_train - X_train_recon) ** 2, axis=1)\n","dae_scores_test  = np.mean((X_test - X_test_recon) ** 2, axis=1)\n","\n","# --- Step 2: Normalize & Augment ---\n","scaler = MinMaxScaler()\n","train_scores = scaler.fit_transform(np.vstack([if_scores_train, dae_scores_train]).T)\n","test_scores  = scaler.transform(np.vstack([if_scores_test, dae_scores_test]).T)\n","\n","X_train_aug = np.hstack([X_train, train_scores])\n","X_test_aug  = np.hstack([X_test, test_scores])\n","\n","joblib.dump(scaler, MODEL_DIR / \"unsw_minmax_scaler.pkl\")\n","print(\"Original features:\", X_train.shape[1])\n","print(\"New features (augmented):\", X_train_aug.shape[1])\n","\n","# --- Step 3: Compute Class Weights ---\n","classes, counts = np.unique(y_train, return_counts=True)\n","total = len(y_train)\n","n_classes = len(classes)\n","\n","class_weights = {c: total / (n_classes * cnt) for c, cnt in zip(classes, counts)}\n","print(\"\\nClass Weights:\", class_weights)\n","\n","sample_weights = np.array([class_weights[int(y)] for y in y_train])\n","\n","# --- Step 4: Train Enhanced Multi-class XGBoost ---\n","num_classes = n_classes\n","xgb_model = XGBClassifier(\n","    n_estimators=500,\n","    learning_rate=0.1,\n","    max_depth=8,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    objective=\"multi:softprob\",\n","    num_class=num_classes,\n","    n_jobs=-1,\n","    eval_metric=\"mlogloss\"\n",")\n","\n","xgb_model.fit(X_train_aug, y_train, sample_weight=sample_weights)\n","\n","# --- Step 5: Evaluate Default Predictions ---\n","y_pred = xgb_model.predict(X_test_aug)\n","y_prob = xgb_model.predict_proba(X_test_aug)\n","\n","print(\"\\n=== Confusion Matrix (Default) ===\")\n","print(confusion_matrix(y_test, y_pred))\n","\n","print(\"\\n=== Classification Report (Default) ===\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","y_test_bin = label_binarize(y_test, classes=np.arange(num_classes))\n","roc_macro = roc_auc_score(y_test_bin, y_prob, average=\"macro\", multi_class=\"ovr\")\n","roc_per_class = roc_auc_score(y_test_bin, y_prob, average=None, multi_class=\"ovr\")\n","print(\"\\nMacro ROC-AUC:\", roc_macro)\n","print(\"Per-Class ROC-AUC:\", dict(zip(range(num_classes), roc_per_class)))\n","\n","# --- Step 6: Threshold Tuning (per class) ---\n","best_thresholds = {}\n","y_pred_thresh = np.zeros_like(y_test)\n","\n","for c in range(num_classes):\n","    best_f1, best_t = 0, 0.5\n","    for t in np.linspace(0.1, 0.9, 17):\n","        preds = (y_prob[:, c] >= t).astype(int)\n","        f1 = f1_score((y_test == c).astype(int), preds)\n","        if f1 > best_f1:\n","            best_f1, best_t = f1, t\n","    best_thresholds[c] = best_t\n","\n","# Apply thresholds: pick class if prob >= threshold, else fallback to highest prob\n","for i in range(len(y_test)):\n","    chosen = [c for c in range(num_classes) if y_prob[i, c] >= best_thresholds[c]]\n","    y_pred_thresh[i] = chosen[0] if chosen else np.argmax(y_prob[i])\n","\n","print(\"\\n=== Confusion Matrix (Threshold Adjusted) ===\")\n","print(confusion_matrix(y_test, y_pred_thresh))\n","\n","print(\"\\n=== Classification Report (Threshold Adjusted) ===\")\n","print(classification_report(y_test, y_pred_thresh, digits=4))\n","\n","# --- Step 7: Save Enhanced Model + Thresholds ---\n","joblib.dump({\n","    \"model\": xgb_model,\n","    \"scaler\": scaler,\n","    \"thresholds\": best_thresholds\n","}, MODEL_DIR / \"unsw_xgb_enhanced.pkl\")\n","\n","print(\"\\nEnhanced UNSW XGBoost model + thresholds saved!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dq5-fJ89LhYJ","executionInfo":{"status":"ok","timestamp":1759083236721,"user_tz":-330,"elapsed":2581455,"user":{"displayName":"Lekzang Jigme","userId":"15030187845076288727"}},"outputId":"bf61fa0b-1b8e-4b8f-8ad3-280fa0edc276"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (1647530, 24)  Test shape: (411883, 24)\n","Original features: 24\n","New features (augmented): 26\n","\n","Class Weights: {np.int32(0): np.float64(85.73294478846854), np.int32(1): np.float64(111.19187419855571), np.int32(2): np.float64(626.6755420311906), np.int32(3): np.float64(33.04842333306588), np.int32(4): np.float64(6.783615858755131), np.int32(5): np.float64(8.590012304740453), np.int32(6): np.float64(7.377374374221976), np.int32(7): np.float64(0.09553127059900814), np.int32(8): np.float64(14.016044782468141), np.int32(9): np.float64(123.8837506579442), np.int32(10): np.float64(1093.2514930325149)}\n","\n","=== Confusion Matrix (Default) ===\n","[[   105    216     49     38      8      3      5      6      7      0\n","       0]\n"," [   209     63      0     36     14      5      3      0      5      2\n","       0]\n"," [    37      0     10      5      4      2      0      0      2      0\n","       0]\n"," [   111    191     32    283    382     27     18      1     41     44\n","       3]\n"," [   131    197     46    323   4318    100     83     10    238     63\n","      11]\n"," [   117    202     39     25     48   3852      8     19     10     39\n","       0]\n"," [   105    207      1     50    222     36   4426      1      7     21\n","       0]\n"," [   395     10      2     70    322   4311     14 386694     83     51\n","       2]\n"," [   117    207      1     16    126      9      3      2   2175     15\n","       0]\n"," [     0      1      0     16     29     19     10      0     18    209\n","       0]\n"," [     0      1      0      4     12      0      3      0      0      0\n","      14]]\n","\n","=== Classification Report (Default) ===\n","              precision    recall  f1-score   support\n","\n","           0     0.0791    0.2403    0.1190       437\n","           1     0.0486    0.1869    0.0772       337\n","           2     0.0556    0.1667    0.0833        60\n","           3     0.3268    0.2498    0.2831      1133\n","           4     0.7872    0.7822    0.7847      5520\n","           5     0.4605    0.8837    0.6055      4359\n","           6     0.9679    0.8719    0.9174      5076\n","           7     0.9999    0.9866    0.9932    391954\n","           8     0.8411    0.8143    0.8275      2671\n","           9     0.4707    0.6921    0.5603       302\n","          10     0.4667    0.4118    0.4375        34\n","\n","    accuracy                         0.9764    411883\n","   macro avg     0.5004    0.5715    0.5172    411883\n","weighted avg     0.9857    0.9764    0.9802    411883\n","\n","\n","Macro ROC-AUC: 0.9971241791333694\n","Per-Class ROC-AUC: {0: np.float64(0.9946594168953785), 1: np.float64(0.9961257219844731), 2: np.float64(0.9991357330697896), 3: np.float64(0.9904039700910923), 4: np.float64(0.9972586652998584), 5: np.float64(0.9952159269887038), 6: np.float64(0.998948311316273), 7: np.float64(0.9992103081452712), 8: np.float64(0.998873621606349), 9: np.float64(0.999086039262813), 10: np.float64(0.9994482558070613)}\n","\n","=== Confusion Matrix (Threshold Adjusted) ===\n","[[   270     98     49     14      1      1      2      0      2      0\n","       0]\n"," [   248     52      0     15     13      3      2      0      3      1\n","       0]\n"," [    40      0      8      5      4      1      0      0      2      0\n","       0]\n"," [   310     41     14    331    327     21     15      3     25     43\n","       3]\n"," [   351     73     15    439   4247     84     69     14    158     58\n","      12]\n"," [   304     49     21     21     58   3615      8    238      8     36\n","       1]\n"," [   269     59      1     48    254     27   4386      6      6     20\n","       0]\n"," [   580     26      3     47    303   2773     12 388090     75     43\n","       2]\n"," [   292     45      1     16    179      6      2      2   2113     15\n","       0]\n"," [     1      5      0     15     32     16     10      3     15    205\n","       0]\n"," [     0      4      0      1     12      0      3      0      0      0\n","      14]]\n","\n","=== Classification Report (Threshold Adjusted) ===\n","              precision    recall  f1-score   support\n","\n","           0     0.1013    0.6178    0.1741       437\n","           1     0.1150    0.1543    0.1318       337\n","           2     0.0714    0.1333    0.0930        60\n","           3     0.3477    0.2921    0.3175      1133\n","           4     0.7821    0.7694    0.7757      5520\n","           5     0.5522    0.8293    0.6629      4359\n","           6     0.9727    0.8641    0.9152      5076\n","           7     0.9993    0.9901    0.9947    391954\n","           8     0.8779    0.7911    0.8322      2671\n","           9     0.4869    0.6788    0.5671       302\n","          10     0.4375    0.4118    0.4242        34\n","\n","    accuracy                         0.9792    411883\n","   macro avg     0.5222    0.5938    0.5353    411883\n","weighted avg     0.9865    0.9792    0.9823    411883\n","\n","\n","Enhanced UNSW XGBoost model + thresholds saved!\n"]}]}]}